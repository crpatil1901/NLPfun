{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 23269\n",
      "Length of tokens: 24531\n"
     ]
    }
   ],
   "source": [
    "file = open('text.txt', 'r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "tokens = [int(token) for token in text.encode()]\n",
    "print(f\"Length of text: {len(text)}\")\n",
    "print(f\"Length of tokens: {len(tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbpc(bytes):\n",
    "    bpc = dict()\n",
    "    for b1, b2 in zip(bytes, bytes[1:]):\n",
    "        cnt = bpc.get((b1, b2), 0)\n",
    "        bpc[(b1, b2)] = cnt+1\n",
    "    return bpc\n",
    "\n",
    "def replace(tokens, pair, newid):\n",
    "    toknew = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i == len(tokens) - 1: toknew.append(tokens[i]); break\n",
    "        if tokens[i] == pair[0] and tokens[i+1] == pair[1]:\n",
    "            toknew.append(newid); i += 2\n",
    "        else: toknew.append(tokens[i]); i += 1\n",
    "    return toknew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink(vs, tokens, show_stats = False):\n",
    "    if show_stats:\n",
    "        tokcntstat = np.zeros(vs - 255)\n",
    "        lenstat = np.zeros(vs - 255)\n",
    "        diffstat = np.zeros(vs - 255)\n",
    "    tokcnt = 255\n",
    "    merges = {}\n",
    "    tokentemp = tokens.copy()\n",
    "    while tokcnt < vs:\n",
    "        bpc = getbpc(tokentemp)\n",
    "        pair = max(bpc, key=bpc.get)\n",
    "        tokcnt += 1\n",
    "        merges[pair] = tokcnt\n",
    "        toknew = replace(tokentemp, pair, tokcnt)\n",
    "        if show_stats:\n",
    "            tokcntstat[vs - tokcnt] = tokcnt\n",
    "            lenstat[vs - tokcnt] = len(toknew)\n",
    "            diffstat[vs - tokcnt] = len(tokentemp) - len(toknew)\n",
    "        tokentemp = toknew\n",
    "    if show_stats:\n",
    "        plt.figure()\n",
    "        plt.plot(tokcntstat, diffstat)\n",
    "        compressionRatios = len(tokens) / lenstat\n",
    "        plt.figure()\n",
    "        plt.plot(tokcntstat, lenstat)\n",
    "        plt.figure()\n",
    "        plt.plot(tokcntstat, (compressionRatios))\n",
    "    return (tokentemp, merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stokens, merges = shrink(300, tokens, show_stats=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {i: bytes([i]) for i in range(256)}\n",
    "for (a, b), c in merges.items():\n",
    "    vocab[c] = vocab[a] + vocab[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ids):\n",
    "    tokens = b\"\".join(vocab[idx] for idx in ids)\n",
    "    return tokens.decode(\"utf-8\", errors='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(text):\n",
    "    tokens = list(text.encode(\"utf-8\"))\n",
    "    if len(tokens) < 2: return tokens\n",
    "    while True:\n",
    "        bpc = getbpc(tokens)\n",
    "        pair = min(bpc, key=lambda p: merges.get(p, float(\"inf\")))\n",
    "        if pair not in merges: break\n",
    "        idx = merges[pair]\n",
    "        tokens = replace(tokens, pair, idx)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n"
     ]
    }
   ],
   "source": [
    "print(decode(encode(\"Hello World\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HELLO', \"'S\", ' World', '123', ' how', \"'ve\", '     ', ' are', ' you', '!!!?']\n"
     ]
    }
   ],
   "source": [
    "patterns = [\n",
    "    r\"\"\"'s|'t|'re|'ve|'m|'ll|'d\"\"\", # Common suffixes in english language\n",
    "    r\"\"\" ?\\p{L}+\"\"\", # Optional space followed by a series of letters\n",
    "    r\"\"\" ?\\p{N}+\"\"\", # Optional space followed by a series of numbers\n",
    "    r\"\"\" ?[^\\s\\p{L}\\p{N}]+\"\"\",\n",
    "    r\"\"\"\\s+(?!\\S)\"\"\", # Any ammount of Symbols\n",
    "    r\"\"\"\\s+\"\"\",\n",
    "]\n",
    "\n",
    "fullpat = re.compile(r\"(?i:\"+r\"|\".join(patterns) + r\")\", flags=re.IGNORECASE)\n",
    "print(re.findall(fullpat, \"HELLO'S World123 how've      are you!!!?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

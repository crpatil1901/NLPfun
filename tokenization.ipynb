{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 23269\n",
      "Length of tokens: 24531\n"
     ]
    }
   ],
   "source": [
    "file = open('text.txt', 'r')\n",
    "text = file.read()\n",
    "file.close()\n",
    "tokens = [int(token) for token in text.encode()]\n",
    "print(f\"Length of text: {len(text)}\")\n",
    "print(f\"Length of tokens: {len(tokens)}\")\n",
    "# print(f\"Text: {text}\")\n",
    "# print(f\"Tokens: {tokens}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getbpc(bytes):\n",
    "    bpc = dict()\n",
    "    for b1, b2 in zip(bytes, bytes[1:]):\n",
    "        cnt = bpc.get((b1, b2), 0)\n",
    "        bpc[(b1, b2)] = cnt+1\n",
    "    return bpc\n",
    "\n",
    "def replace(tokens, pair, newid):\n",
    "    toknew = []\n",
    "    i = 0\n",
    "    while i < len(tokens):\n",
    "        if i == len(tokens) - 1: toknew.append(tokens[i]); break\n",
    "        if tokens[i] == pair[0] and tokens[i+1] == pair[1]:\n",
    "            toknew.append(newid); i += 2\n",
    "        else: toknew.append(tokens[i]); i += 1\n",
    "    return toknew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shrink(vs, tokens, show_stats = False):\n",
    "    if show_stats:\n",
    "        tokcntstat = np.zeros(vs - 255)\n",
    "        lenstat = np.zeros(vs - 255)\n",
    "        diffstat = np.zeros(vs - 255)\n",
    "    tokcnt = 255\n",
    "    merges = {}\n",
    "    tokentemp = tokens.copy()\n",
    "    while tokcnt < vs:\n",
    "        bpc = getbpc(tokentemp)\n",
    "        pair = max(bpc, key=bpc.get)\n",
    "        tokcnt += 1\n",
    "        merges[pair] = tokcnt\n",
    "        toknew = replace(tokentemp, pair, tokcnt)\n",
    "        if show_stats:\n",
    "            tokcntstat[vs - tokcnt] = tokcnt\n",
    "            lenstat[vs - tokcnt] = len(toknew)\n",
    "            diffstat[vs - tokcnt] = len(tokentemp) - len(toknew)\n",
    "        tokentemp = toknew\n",
    "    if show_stats:\n",
    "        plt.figure()\n",
    "        plt.plot(tokcntstat, diffstat)\n",
    "        compressionRatios = len(tokens) / lenstat\n",
    "        plt.figure()\n",
    "        plt.plot(tokcntstat, lenstat)\n",
    "        plt.figure()\n",
    "        plt.plot(tokcntstat, (compressionRatios))\n",
    "    return (tokentemp, merges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stokens, merges = shrink(300, tokens, show_stats=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {i: bytes([i]) for i in range(256)}\n",
    "for (a, b), c in merges.items():\n",
    "    vocab[c] = vocab[a] + vocab[b]\n",
    "    # print(vocab[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(ids):\n",
    "    decoded = []\n",
    "    for i in ids:\n",
    "        decoded += vocab[i]\n",
    "    return decoded\n",
    "\n",
    "# str(bytes(decode(stokens)), encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
